interface ProperNoun {
  original: string;
  translation: string;
}

/**
 * ê³ ìœ ëª…ì‚¬ë¥¼ í† í°ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” í•¨ìˆ˜
 */
export const replaceProperNounsWithTokens = (
  text: string,
  properNouns: ProperNoun[]
) => {
  let tokenMap: { [key: string]: string } = {};
  let transformedText = text;

  properNouns.forEach((noun, index) => {
    // í† í° í˜•ì‹ì„ ë³€ê²½í•˜ì—¬ ë‹¨ì–´ë¡œ ì¸ì‹ë˜ì§€ ì•Šë„ë¡ í•¨
    // Proper _ Noun _ index
    const token = `**P_N_${index}**`;
    const regex = new RegExp(`\\b${noun.original}\\b`, "g");
    transformedText = transformedText.replace(regex, token);
    tokenMap[token] = noun.translation;
  });

  console.log("ğŸ“Œ í† í°ìœ¼ë¡œ ëŒ€ì²´ëœ í…ìŠ¤íŠ¸:", transformedText);
  console.log("ğŸ“Œ í† í° ë§µ:", tokenMap);

  return { transformedText, tokenMap };
};

/**
 * í† í°ì„ ì›ë˜ì˜ ê³ ìœ ëª…ì‚¬ë¡œ ë³µì›í•˜ëŠ” í•¨ìˆ˜
 */
export const restoreProperNounsFromTokens = (
  text: string,
  tokenMap: { [key: string]: string }
) => {
  let restoredText = text;

  Object.keys(tokenMap).forEach((token) => {
    const regex = new RegExp(token, "g");
    restoredText = restoredText.replace(regex, tokenMap[token]);
  });

  console.log("ğŸ“Œ í† í°ì´ ë³µì›ëœ í…ìŠ¤íŠ¸:", restoredText);

  return restoredText;
};

/**
 * âœ… Zero Width Non-Joiner (\u200C) ì‚½ì… í•¨ìˆ˜
 */
export function addInvisibleCharacters(text: string): string {
  return text.split("").join("\u200C"); // ê° ë¬¸ì ì‚¬ì´ì— ZWNJ ì¶”ê°€
}

/**
 * âœ… Zero Width Non-Joiner (\u200C) ì œê±° í•¨ìˆ˜ (ë³µêµ¬)
 */
export function removeInvisibleCharacters(text: string): string {
  return text.replace(/\u200C/g, ""); // ëª¨ë“  ZWNJ ì œê±°
}
